{
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# NOTE\n",
        "\n",
        "For Spark 3 Cosmos DB connector has slightly different configuration. Please select different snippest if a Spark 3.1 + pool is attached."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "outputs": [],
      "metadata": {},
      "source": [
        "# Load a streaming Spark DataFrame from a Cosmos DB container\n",
        "# To select a preferred list of regions in a multi-region Cosmos DB account, add .option(\"spark.cosmos.preferredRegions\", \"<Region1>,<Region2>\")\n",
        "\n",
        "# For Spark 2.4\n",
        "# dfStream = spark.readStream\\\n",
        "#     .format(\"cosmos.oltp\")\\\n",
        "#     .option(\"spark.synapse.linkedService\", \"CosmosDbNoSql1\")\\\n",
        "#     .option(\"spark.cosmos.container\", \"orders\")\\\n",
        "#     .option(\"spark.cosmos.changeFeed.readEnabled\", \"true\")\\\n",
        "#     .option(\"spark.cosmos.changeFeed.startFromTheBeginning\", \"true\")\\\n",
        "#     .option(\"spark.cosmos.changeFeed.checkpointLocation\", \"/localReadCheckpointFolder\")\\\n",
        "#     .option(\"spark.cosmos.changeFeed.queryName\", \"streamQuery\")\\\n",
        "#     .load()\n",
        "\n",
        "# For Spark 3.1 +\n",
        "dfStream = spark.readStream\\\n",
        "    .format(\"cosmos.oltp.changeFeed\")\\\n",
        "    .option(\"spark.synapse.linkedService\", \"CosmosDbNoSql1\")\\\n",
        "    .option(\"spark.cosmos.container\", \"orders\")\\\n",
        "    .option(\"spark.cosmos.changeFeed.startFrom\", \"Beginning\")\\\n",
        "    .option(\"spark.cosmos.changeFeed.mode\", \"Incremental\")\\\n",
        "    .load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "from   pyspark.sql.functions import * "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "dfStream"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "dfStream=dfStream.withColumn(\"Order_Timestamp\",to_timestamp(\"Order_Timestamp\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "dfStream.writeStream.outputMode(\"append\").format(\"delta\").option(\"path\",\"abfss://streamsynapse@synapasestream.dfs.core.windows.net/synapse/workspaces/streamoutput/\").option(\"checkpointLocation\",\"abfss://streamsynapse@synapasestream.dfs.core.windows.net/synapse/workspaces/checkpoint/\").start()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "collapsed": false
      },
      "source": [
        "display(spark.read.load('abfss://streamsynapse@synapasestream.dfs.core.windows.net/synapse/workspaces/streamoutput/'))"
      ]
    }
  ],
  "metadata": {
    "save_output": true,
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    }
  }
}