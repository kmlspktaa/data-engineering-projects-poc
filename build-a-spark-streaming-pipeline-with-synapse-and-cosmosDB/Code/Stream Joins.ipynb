{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# NOTE\n",
        "\n",
        "For Spark 3 Cosmos DB connector has slightly different configuration. Please select different snippest if a Spark 3.1 + pool is attached."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "outputs": [],
      "metadata": {},
      "source": [
        "# Load a streaming Spark DataFrame from a Cosmos DB container\n",
        "# To select a preferred list of regions in a multi-region Cosmos DB account, add .option(\"spark.cosmos.preferredRegions\", \"<Region1>,<Region2>\")\n",
        "\n",
        "# For Spark 2.4\n",
        "# dfStream = spark.readStream\\\n",
        "#     .format(\"cosmos.oltp\")\\\n",
        "#     .option(\"spark.synapse.linkedService\", \"CosmosDbNoSql1\")\\\n",
        "#     .option(\"spark.cosmos.container\", \"orders\")\\\n",
        "#     .option(\"spark.cosmos.changeFeed.readEnabled\", \"true\")\\\n",
        "#     .option(\"spark.cosmos.changeFeed.startFromTheBeginning\", \"true\")\\\n",
        "#     .option(\"spark.cosmos.changeFeed.checkpointLocation\", \"/localReadCheckpointFolder\")\\\n",
        "#     .option(\"spark.cosmos.changeFeed.queryName\", \"streamQuery\")\\\n",
        "#     .load()\n",
        "\n",
        "# For Spark 3.1 +\n",
        "dfStream = spark.readStream\\\n",
        "    .format(\"cosmos.oltp.changeFeed\")\\\n",
        "    .option(\"spark.synapse.linkedService\", \"CosmosDbNoSql1\")\\\n",
        "    .option(\"spark.cosmos.container\", \"orders\")\\\n",
        "    .option(\"spark.cosmos.changeFeed.startFrom\", \"Beginning\")\\\n",
        "    .option(\"spark.cosmos.changeFeed.mode\", \"Incremental\")\\\n",
        "    .load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "from   pyspark.sql.functions import * \r\n",
        "from pyspark.sql import *\r\n",
        "from delta.tables import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "dfStream"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "dfStream=dfStream.withColumn(\"Order_Date\",to_date(\"Order_Timestamp\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "dfStream=dfStream.withColumn(\"Order_Timestamp\",to_timestamp(\"Order_Timestamp\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "dfStream"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "dfStream1=dfStream.withWatermark('Order_Timestamp', '10 minutes').groupBy(\"Item_Id\",\"Order_Date\",window(\"Order_Timestamp\",\"60 minutes\")).agg(sum(\"qty\")).alias(\"sum_qty\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "dfStream1=dfStream1.withColumnRenamed(\"sum(qty)\",\"sum_qty\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "dfStream1=dfStream1.withColumn(\"window_Start_Time\",expr(\"window.start\"))\r\n",
        "dfStream1=dfStream1.withColumn(\"window_end_Time\",expr(\"window.end\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "dfStream1.writeStream.outputMode(\"complete\").format(\"delta\").option(\"path\",\"abfss://streamsynapse@synapasestream.dfs.core.windows.net/synapse/workspaces/streamoutput/Order_stream_output\").option(\"checkpointLocation\",\"abfss://streamsynapse@synapasestream.dfs.core.windows.net/synapse/workspaces/tumb_checkpoint/\").start()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Load a streaming Spark DataFrame from a Cosmos DB container\r\n",
        "# To select a preferred list of regions in a multi-region Cosmos DB account, add .option(\"spark.cosmos.preferredRegions\", \"<Region1>,<Region2>\")\r\n",
        "\r\n",
        "# For Spark 2.4\r\n",
        "# dfStream = spark.readStream\\\r\n",
        "#     .format(\"cosmos.oltp\")\\\r\n",
        "#     .option(\"spark.synapse.linkedService\", \"CosmosDbNoSql1\")\\\r\n",
        "#     .option(\"spark.cosmos.container\", \"orders\")\\\r\n",
        "#     .option(\"spark.cosmos.changeFeed.readEnabled\", \"true\")\\\r\n",
        "#     .option(\"spark.cosmos.changeFeed.startFromTheBeginning\", \"true\")\\\r\n",
        "#     .option(\"spark.cosmos.changeFeed.checkpointLocation\", \"/localReadCheckpointFolder\")\\\r\n",
        "#     .option(\"spark.cosmos.changeFeed.queryName\", \"streamQuery\")\\\r\n",
        "#     .load()\r\n",
        "\r\n",
        "# For Spark 3.1 +\r\n",
        "dfStream2 = spark.readStream\\\r\n",
        "    .format(\"cosmos.oltp.changeFeed\")\\\r\n",
        "    .option(\"spark.synapse.linkedService\", \"CosmosDbNoSql1\")\\\r\n",
        "    .option(\"spark.cosmos.container\", \"Stockitems\")\\\r\n",
        "    .option(\"spark.cosmos.changeFeed.startFrom\", \"Beginning\")\\\r\n",
        "    .option(\"spark.cosmos.changeFeed.mode\", \"Incremental\")\\\r\n",
        "    .load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "dfStream1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "dfStream2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "dfStream2=dfStream2.withColumnRenamed(\"item_id\",\"item_id_refill\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "dfStream2=dfStream2.withColumn(\"refill_timestamp\",to_timestamp(\"refill_timestamp\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "dfStream2=dfStream2.withColumn(\"refill_date\",to_date(\"refill_timestamp\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "dfStream2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "dfStream2=dfStream2.withWatermark('refill_timestamp', '10 minutes').groupBy(\"Item_Id_refill\",\"refill_date\",window(\"refill_timestamp\",\"6 minutes\")).agg(sum(\"stock_Refill_qty\")).alias(\"stock_Refill_qty\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "dfStream2=dfStream2.withColumn(\"stock_start_window\",expr(\"window.start\"))\r\n",
        "dfStream2=dfStream2.withColumn(\"stock_end_window\",expr(\"window.end\"))\r\n",
        "dfStream2=dfStream2.withColumnRenamed(\"sum(stock_Refill_qty)\",\"sum_stock_Refill_qty\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "dfStream2.writeStream.outputMode(\"complete\").format(\"delta\").option(\"path\",\"abfss://streamsynapse@synapasestream.dfs.core.windows.net/synapse/workspaces/streamoutput/item_Refill/\").option(\"checkpointLocation\",\"abfss://streamsynapse@synapasestream.dfs.core.windows.net/synapse/workspaces/item_refill_checkpoint/\").start()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "dfStream4=spark.readStream\\\r\n",
        "    .format(\"delta\")\\\r\n",
        "    .option(\"path\", \"abfss://streamsynapse@synapasestream.dfs.core.windows.net/synapse/workspaces/streamoutput/item_Refill/\")\\\r\n",
        "    .load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "dfStream5=spark.readStream\\\r\n",
        "    .format(\"delta\")\\\r\n",
        "    .option(\"path\", \"abfss://streamsynapse@synapasestream.dfs.core.windows.net/synapse/workspaces/streamoutput/Order_stream_output/\")\\\r\n",
        "    .load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "dfStream6=dfStream5.join(dfStream4,expr(\"Item_Id_refill=item_id and refill_date= Order_Date and stock_start_window= window_Start_Time and window_end_Time=stock_end_window  \" ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "def microbatch(batch_df,batch_id):\r\n",
        "    url=\"\"\r\n",
        "    myobj=\"\"\r\n",
        "    df1=batch_df.withColumn(\"difference_quantity\",expr(\"sum_stock_Refill_qty-sum_qty\"))\r\n",
        "    if df1.filter(df1.difference_quantity<100).count()>1:\r\n",
        "        url = 'https://metadatamanagementemail.azurewebsites.net:443/api/sample_email/triggers/When_a_HTTP_request_is_received/invoke?api-version=2022-05-01&sp=%2Ftriggers%2FWhen_a_HTTP_request_is_received%2Frun&sv=1.0&sig=Lz1K7ZusrhyeY1lxp9zV12sPUJUEHxlHVH1HTwL0MMA'\r\n",
        "        myobj = {\r\n",
        "            \"emailaddress\":\"rohith.amaze@gmail.com\",\r\n",
        "            \"body\":\"triggered from python Databricks stream\",\r\n",
        "            \"subject\":\"Low Stock Alert\"\r\n",
        "        }\r\n",
        "        trigger_email(url,myobj)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "def trigger_email(url,myobj):\r\n",
        "    x = requests.post(url=url, json = myobj)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "dfStream6.writeStream.outputMode(\"append\").foreachBatch(microbatch).option(\"checkpointLocation\",\"/mnt/streamsynapse/synapse/workspaces/join/join_output_chkpoint/\").start()"
      ]
    }
  ]
}