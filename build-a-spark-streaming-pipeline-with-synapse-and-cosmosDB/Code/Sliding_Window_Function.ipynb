{
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "outputs": [],
      "metadata": {},
      "source": [
        "dfStream = spark.readStream\\\r\n",
        "    .format(\"cosmos.oltp.changeFeed\")\\\r\n",
        "    .option(\"spark.synapse.linkedService\", \"CosmosDbNoSql1\")\\\r\n",
        "    .option(\"spark.cosmos.container\", \"orders\")\\\r\n",
        "    .option(\"spark.cosmos.changeFeed.startFrom\", \"Beginning\")\\\r\n",
        "    .option(\"spark.cosmos.changeFeed.mode\", \"Incremental\")\\\r\n",
        "    .load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "from   pyspark.sql.functions import * \r\n",
        "from pyspark.sql import *\r\n",
        "from delta.tables import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "dfStream=dfStream.withColumn(\"Order_Date\",to_date(\"Order_Timestamp\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "dfStream=dfStream.withColumn(\"Order_Timestamp\",to_timestamp(\"Order_Timestamp\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "dfStream1=dfStream.withWatermark('Order_Timestamp', '10 minutes').groupBy(\"Item_Id\",\"Order_Date\",window(\"Order_Timestamp\",\"8 minutes\",\"4 minutes\")).agg(sum(\"qty\")).alias(\"sum_qty\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "dfStream1=dfStream1.withColumnRenamed(\"sum(qty)\",\"sum_qty\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "def microbatch(batch_df,batch_id):\r\n",
        "    delta_table=DeltaTable.forPath(spark, 'abfss://streamsynapse@synapasestream.dfs.core.windows.net/synapse/workspaces/streamoutput/tumbling_window')\r\n",
        "    #print(delta_table)\r\n",
        "    delta_table.alias('target').merge(batch_df.alias('updates'),'target.item_id = updates.item_id and target.window_Start_Time=updates.window_Start_Time and target.window_end_Time=updates.window_end_Time and target.order_date=updates.order_date').whenMatchedUpdateAll().whenNotMatchedInsertAll().execute()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "dfStream1.writeStream.outputMode(\"complete\").format(\"delta\").option(\"path\",\"abfss://streamsynapse@synapasestream.dfs.core.windows.net/synapse/workspaces/streamoutput/sliding_window\").option(\"checkpointLocation\",\"abfss://streamsynapse@synapasestream.dfs.core.windows.net/synapse/workspaces/sliding_window_checkpoint/\").start()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#dfStream1.writeStream.outputMode(\"complete\").foreachBatch(microbatch).option(\"checkpointLocation\",\"abfss://streamsynapse@synapasestream.dfs.core.windows.net/synapse/workspaces/tumb_checkpoint/\").start()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "outputs": [],
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "sparksql"
        },
        "collapsed": false
      },
      "source": [
        "%%sql\r\n",
        "\r\n",
        "select window.start,window.end,a.* from delta.`abfss://streamsynapse@synapasestream.dfs.core.windows.net/synapse/workspaces/streamoutput/sliding_window` a where item_id=10 order by 5 desc"
      ]
    }
  ],
  "metadata": {
    "save_output": true,
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    }
  }
}